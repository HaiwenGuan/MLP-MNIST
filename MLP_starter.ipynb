{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWsI+uTumXbUy4mQrDJDgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaiwenGuan/MLP-MNIST/blob/main/MLP_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports**"
      ],
      "metadata": {
        "id": "THehMjIEXR-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "\n",
        "np.random.seed(4208)\n",
        "tf.random.set_seed(4208)"
      ],
      "metadata": {
        "id": "843yd00FXRVR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.executing_eagerly()\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C2fSADF8G1yO",
        "outputId": "5c419037-8fff-49f4-a1f7-2d999fc13a87"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-UeIfWBXkxk",
        "outputId": "9663bba4-8360-4331-f846-9a065fe2dd15"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate random data"
      ],
      "metadata": {
        "id": "djjVvFhjXuYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_input = 784\n",
        "size_hidden_1 = 256\n",
        "size_hidden_2 = 128\n",
        "size_output = 10"
      ],
      "metadata": {
        "id": "E6V-x93MXsjy"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
        "X_train = tf.cast(tf.reshape(X_train, (-1, 784)), dtype=tf.float32)\n",
        "X_test = tf.cast(tf.reshape(X_test, (-1, 784)), dtype=tf.float32)\n",
        "y_train = tf.one_hot(y_train, 10)\n",
        "y_test = tf.one_hot(y_test, 10)\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "metadata": {
        "id": "BngVCmxgX8pJ"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "#print(y_train[0])\n",
        "print(tf.shape(X_test))\n",
        "print(tf.shape(y_test))"
      ],
      "metadata": {
        "id": "exdy4cXFISQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(30)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(100)"
      ],
      "metadata": {
        "id": "Q7faEczYYpjf"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build MLP using Eager Execution"
      ],
      "metadata": {
        "id": "IRAaj0uAY_1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden_1, size_hidden_2, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: etiher 'cpu' or 'gpu' or None. If None, decided automatically during eager.\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden_1, self.size_hidden_2, self.size_output, self.device =\\\n",
        "    size_input, size_hidden_1, size_hidden_2, size_output, device\n",
        "\n",
        "    #Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden_1]))\n",
        "    self.b1 = tf.Variable(tf.random.normal([1,self.size_hidden_1]))\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden_1, self.size_hidden_2]))\n",
        "    self.b2 = tf.Variable(tf.random.normal([1,self.size_hidden_2]))\n",
        "    self.Wop = tf.Variable(tf.random.normal([self.size_hidden_2, self.size_output]))\n",
        "    self.bop = tf.Variable(tf.random.normal([1,self.size_output]))\n",
        "\n",
        "    self.variables = [self.W1, self.W2, self.b1, self.b2, self.Wop, self.bop]  # define variables(parameters) that will be updated \n",
        "\n",
        "  def forward(self, X): # (X is the input matrix)\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y=self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "    \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape(batch_size, size_output)\n",
        "    y_true - Tensor of shape(batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "  def backward(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients( zip( grads, self.variables))\n",
        "    \n",
        "  def compute_output(self, X):\n",
        "#    X_tf = tf.cast(X, dytpe=tf.float32)\n",
        "    what1 = tf.matmul(X, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    output = tf.nn.softmax(tf.matmul(hhat2, self.Wop) + self.bop)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "n5D06pB5Y_Xd"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "mvTC-aKeANc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "Ims8PMhtAK7h"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_gpu = MLP(size_input, size_hidden_1, size_hidden_2, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1],dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy = []\n",
        "  m = tf.keras.metrics.CategoricalAccuracy()\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100, seed=epoch*(4208)).batch(100)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    m.update_state(preds,outputs)\n",
        "    accuracy.append(m.result().numpy())\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "  #print('Number of Epoch = {} - Average MSE:= {}'.format(epoch + 1, np.sum(loss_total) / 600))\n",
        "  m.reset_state()\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, np.sum(accuracy)/len(accuracy)))\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "id": "aw5bbqk_AR7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d51c0a-727f-45a4-b806-0b083d89b5fb"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Accuracy:= 0.18871610005696615\n",
            "Number of Epoch = 2 - Accuracy:= 0.30731590270996095\n",
            "Number of Epoch = 3 - Accuracy:= 0.3425794219970703\n",
            "Number of Epoch = 4 - Accuracy:= 0.37742151896158854\n",
            "Number of Epoch = 5 - Accuracy:= 0.4426384989420573\n",
            "Number of Epoch = 6 - Accuracy:= 0.476187998453776\n",
            "Number of Epoch = 7 - Accuracy:= 0.49362213134765626\n",
            "Number of Epoch = 8 - Accuracy:= 0.5032605997721354\n",
            "Number of Epoch = 9 - Accuracy:= 0.5099298095703125\n",
            "Number of Epoch = 10 - Accuracy:= 0.5243195597330729\n",
            "\n",
            "Total time taken (in seconds): 387.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0,dtype=tf.float32)\n",
        "accuracy = []\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "  m.update_state(preds,outputs)\n",
        "  accuracy.append(m.result().numpy())\n",
        "#print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(np.sum(accuracy) / len(accuracy)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLJG4b_fw_jL",
        "outputId": "0e845892-2643-40ea-8b2f-a0c0bf219f38"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8691\n"
          ]
        }
      ]
    }
  ]
}