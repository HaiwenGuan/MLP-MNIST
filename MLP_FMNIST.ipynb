{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_FMNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnA4/iUgGjeKJISsiadiUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaiwenGuan/MLP-MNIST/blob/main/MLP_FMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKwgPENlCjTO",
        "outputId": "d5075b24-d3f7-4d50-9eba-dc7cc70fd5cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "np.random.seed(4208)\n",
        "tf.random.set_seed(4208)\n",
        "\n",
        "tf.executing_eagerly()\n",
        "tf.__version__\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size_input = 784\n",
        "size_hidden_1 = 256\n",
        "size_hidden_2 = 128\n",
        "size_output = 10"
      ],
      "metadata": {
        "id": "4nULhUrXCq5j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = tf.cast(tf.reshape(X_train, (-1, 784)), dtype=tf.float32)\n",
        "X_test = tf.cast(tf.reshape(X_test, (-1, 784)), dtype=tf.float32)\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(100)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(20)"
      ],
      "metadata": {
        "id": "oz5ucZYHCu2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea2c73d-2b4c-42ed-f749-ee88124db6b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.shape(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjb54HqDEinY",
        "outputId": "eeec3f75-a736-4185-f423-01f6c68581da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([60000], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden_1, size_hidden_2, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: etiher 'cpu' or 'gpu' or None. If None, decided automatically during eager.\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden_1, self.size_hidden_2, self.size_output, self.device =\\\n",
        "    size_input, size_hidden_1, size_hidden_2, size_output, device\n",
        "\n",
        "    #Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden_1]))\n",
        "    self.b1 = tf.Variable(tf.random.normal([1,self.size_hidden_1]))\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden_1, self.size_hidden_2]))\n",
        "    self.b2 = tf.Variable(tf.random.normal([1,self.size_hidden_2]))\n",
        "    self.Wop = tf.Variable(tf.random.normal([self.size_hidden_2, self.size_output]))\n",
        "    self.bop = tf.Variable(tf.random.normal([1,self.size_output]))\n",
        "\n",
        "    self.variables = [self.W1, self.W2, self.b1, self.b2, self.Wop, self.bop]  # define variables(parameters) that will be updated \n",
        "\n",
        "  def forward(self, X): # (X is the input matrix)\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "    \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape(batch_size, size_output)\n",
        "    y_true - Tensor of shape(batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    return scce(y_true, y_pred)\n",
        "\n",
        "  def loss_l1(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape(batch_size, size_output)\n",
        "    y_true - Tensor of shape(batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    penalty = (tf.reduce_sum(tf.math.abs(self.W1)).numpy() + tf.reduce_sum(tf.math.abs(self.W2)).numpy()\\\n",
        "               + tf.reduce_sum(tf.math.abs(self.Wop).numpy())) \\\n",
        "               / ( tf.size(self.W1).numpy() + tf.size(self.W2).numpy() + tf.size(self.Wop).numpy() )\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    return scce(y_true, y_pred) + penalty\n",
        "\n",
        "  def loss_l2(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape(batch_size, size_output)\n",
        "    y_true - Tensor of shape(batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    penalty = (tf.reduce_sum(tf.math.square(self.W1)).numpy() + tf.reduce_sum(tf.math.square(self.W2)).numpy() \\\n",
        "               + tf.reduce_sum(tf.math.square(self.Wop)).numpy())\\\n",
        "               / ( tf.size(self.W1).numpy() + tf.size(self.W2).numpy() + tf.size(self.Wop).numpy() )\n",
        "    #penalty = self.l2 * (tf.reduce_sum(tf.math.square(self.W1)).numpy() + tf.reduce_sum(tf.math.square(self.W2)).numpy() + tf.reduce_sum(tf.math.square(self.Wop).numpy()))\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    return scce(y_true, y_pred) + penalty\n",
        "\n",
        "  def backward(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients( zip( grads, self.variables))\n",
        "\n",
        "  def backward_1(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss_l1(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients( zip( grads, self.variables))\n",
        "\n",
        "  def backward_2(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss_l2(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients( zip( grads, self.variables))\n",
        "    \n",
        "  def compute_output(self, X):\n",
        "#    X_tf = tf.cast(X, dytpe=tf.float32)\n",
        "    what1 = tf.matmul(X, self.W1) + self.b1\n",
        "    hhat1 = tf.keras.activations.relu(what1)\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.keras.activations.relu(what2)\n",
        "#    output = tf.nn.softmax(tf.matmul(hhat2, self.Wop) + self.bop)\n",
        "    output = tf.matmul(hhat2, self.Wop) + self.bop\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "5zz7tKLkC5Nf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "vq0cwJ9OEBrc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_gpu = MLP(size_input, size_hidden_1, size_hidden_2, size_output, device='gpu')\n",
        "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1],dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy = []\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100, seed=epoch*(4208)).batch(100)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_gpu.loss_1(preds, outputs)\n",
        "    #lt = lt + mlp_on_gpu.loss(outputs, preds)\n",
        "    m.update_state(outputs,preds)\n",
        "    accuracy.append(m.result().numpy())\n",
        "    mlp_on_gpu.backward_1(inputs, outputs)\n",
        "  #print('Number of Epoch = {} - Average Loss:= {}'.format(epoch + 1, np.sum(loss_total) / 600))\n",
        "  m.reset_state()\n",
        "  print('Number of Epoch = {} - Accuracy:= {} - Average Loss:= {}'.format(epoch + 1, np.sum(accuracy)/len(accuracy), np.sum(loss_total)/X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMJybbEIECRf",
        "outputId": "22750a4c-0ccc-479d-ea61-04f6181a9797"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Accuracy:= 0.5991901652018229 - Average Loss:= 1.455801953125\n",
            "Number of Epoch = 2 - Accuracy:= 0.7549476623535156 - Average Loss:= 0.6576636067708334\n",
            "Number of Epoch = 3 - Accuracy:= 0.7735118611653646 - Average Loss:= 0.490291796875\n",
            "Number of Epoch = 4 - Accuracy:= 0.7838095092773437 - Average Loss:= 0.3973400065104167\n",
            "Number of Epoch = 5 - Accuracy:= 0.7853821309407553 - Average Loss:= 0.33701832682291666\n",
            "Number of Epoch = 6 - Accuracy:= 0.7925965881347656 - Average Loss:= 0.29116360677083336\n",
            "Number of Epoch = 7 - Accuracy:= 0.7984589640299479 - Average Loss:= 0.2563765625\n",
            "Number of Epoch = 8 - Accuracy:= 0.7991684977213541 - Average Loss:= 0.22992298177083334\n",
            "Number of Epoch = 9 - Accuracy:= 0.8007133992513021 - Average Loss:= 0.206908984375\n",
            "Number of Epoch = 10 - Accuracy:= 0.8031553141276042 - Average Loss:= 0.18860901692708334\n",
            "\n",
            "Total time taken (in seconds): 180.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0,dtype=tf.float32)\n",
        "accuracy = []\n",
        "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "  m.update_state(outputs,preds)\n",
        "  accuracy.append(m.result().numpy())\n",
        "#print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))\n",
        "print('Accuracy: {:.4f} - Loss: {:.4f}'.format(np.sum(accuracy) / len(accuracy), np.sum(test_loss_total.numpy()) / X_train.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itwcAv4QIS3M",
        "outputId": "ae9ae3d0-9019-47b5-abc5-728b2ab0130e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7848 - Loss: 0.1832\n"
          ]
        }
      ]
    }
  ]
}